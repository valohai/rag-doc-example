- step:
    name: create-embeddings
    image: ghcr.io/astral-sh/uv:python3.11-bookworm-slim
    command: uv run rag-doctor create-database {parameters}
    parameters:
      - name: content_column_index
        description: Index of the document content column in the CSV files
        type: integer
        default: 0
      - name: source_column_index
        description: Index of the source link column in the CSV files
        type: integer
        default: 1
      - name: header_row_skip
        description: Number of initial rows to skip in the CSV files i.e. the header rows
        type: integer
        default: 0
      - name: provider                    
        description: LLM provider to use (openai or anthropic)
        type: string
        default: openai
        choices: [openai, anthropic]      
    inputs:
      - name: documentation_csv
        description: CSV file(s) containing the technical documentation
        default: https://valohai-examples.s3.amazonaws.com/rag-doc/huggingface-docs.csv

- step:
    name: do-query
    image: ghcr.io/astral-sh/uv:python3.11-bookworm-slim
    command: uv run rag-doctor query {parameters}
    parameters:
      - name: question
        description: The question(s) to ask about the documentation
        type: string
        multiple: repeat
      - name: provider                   
        description: LLM provider to use (openai or anthropic)
        type: string
        default: openai
        choices: [openai, anthropic]      
    inputs:
      - name: embedding_db
        description: Zip archive containing the Qdrant vector database for the embeddings

- endpoint:
    name: ask
    image: ghcr.io/astral-sh/uv:python3.11-bookworm-slim
    port: 8000
    server-command: uv run --group server rag-doctor serve --host 0.0.0.0 --database_dir ./qdrant_data --provider openai
    files:
      - name: embedding_db
        path: qdrant_data/embeddings.zip
        description: Zip archive containing the Qdrant vector database for the embeddings

- pipeline:
    name: assistant-pipeline
    nodes:
      - name: embeddings
        type: execution
        step: create-embeddings
        override:                        
          parameters:
            - name: provider
              default: anthropic
      - name: manual-evaluation
        type: execution
        step: do-query
        override:
          parameters:
            - name: question
              default: ["who is Michael Jordan?", "what is a dataset?", "hello", "how to create a model?"]
            - name: provider              
              default: anthropic
    edges:
      - [embeddings.output.*, manual-evaluation.input.embedding_db]


- pipeline:
    name: assistant-pipeline-with-deployment
    nodes:
      - name: embeddings
        type: execution
        step: create-embeddings
      - name: manual-evaluation
        type: execution
        step: do-query
        override:
          parameters:
            - name: question
              default: ["who is Michael Jordan?", "what is a dataset?", "hello", "how to create a model?"]
      - name: deploy
        type: deployment
        deployment: public
        endpoints: [ask]
        actions:
          - when: node-starting
            then: require-approval
    edges:
      - [embeddings.output.*, manual-evaluation.input.embedding_db]
      - [embeddings.output.*, deploy.file.ask.embedding_db]
